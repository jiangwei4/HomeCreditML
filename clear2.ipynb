{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from math import *\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "mirrored_strategy = tf.distribute.MirroredStrategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('home-credit-default-risk//application_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on suppr toutes les colonnes à plus de 90% de val manquante\n",
    "df = df[df.columns[(df.isna().sum()/df.shape[0]) < 0.9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(total=1)\n",
    "for col in df.select_dtypes('object'):\n",
    "    print(f'{col :-<40} => {df[col].unique()}')\n",
    "    plt.figure()\n",
    "    df[col].value_counts(normalize=True, dropna=False).plot.pie()\n",
    "    pbar.update(1/len(df.select_dtypes('object')))\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corelation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix = df.corr()\n",
    "corrMatrix['TARGET'].sort_values(ascending=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix['TARGET'].sort_values(ascending=False) >0.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatrix['TARGET'].sort_values(ascending=False) <-0.06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df[['TARGET','ORGANIZATION_TYPE','CODE_GENDER','DAYS_BIRTH','REGION_RATING_CLIENT_W_CITY','EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']]\n",
    "#df = df [['TARGET','REGION_RATING_CLIENT_W_CITY','AMT_INCOME_TOTAL','OBS_30_CNT_SOCIAL_CIRCLE','FLAG_PHONE','HOUR_APPR_PROCESS_START','DAYS_REGISTRATION','FLAG_DOCUMENT_3','AMT_ANNUITY','DAYS_ID_PUBLISH','REGION_RATING_CLIENT','CNT_FAM_MEMBERS','REGION_POPULATION_RELATIVE','DAYS_BIRTH','DAYS_LAST_PHONE_CHANGE','FLAG_WORK_PHONE','REG_CITY_NOT_WORK_CITY','AMT_GOODS_PRICE','EXT_SOURCE_1','FLAG_OWN_CAR','AMT_REQ_CREDIT_BUREAU_YEAR','EXT_SOURCE_2','EXT_SOURCE_3']]\n",
    "#df = df[['ORGANIZATION_TYPE', 'ELEVATORS_AVG', 'NAME_FAMILY_STATUS', 'WALLSMATERIAL_MODE','FLAG_DOCUMENT_5', 'OCCUPATION_TYPE', 'FLAG_OWN_CAR', 'YEARS_BEGINEXPLUATATION_AVG', 'FLAG_DOCUMENT_17', 'WEEKDAY_APPR_PROCESS_START', 'LIVINGAREA_AVG', 'NONLIVINGAREA_AVG', 'DAYS_ID_PUBLISH', 'REGION_POPULATION_RELATIVE', 'FLAG_OWN_REALTY', 'APARTMENTS_MODE', 'FONDKAPREMONT_MODE', 'CODE_GENDER', 'BASEMENTAREA_MODE', 'NAME_CONTRACT_TYPE', 'HOUSETYPE_MODE', 'FLOORSMAX_MODE', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'TARGET', 'NAME_TYPE_SUITE']]\n",
    "#df = df[['ORGANIZATION_TYPE','CODE_GENDER','FLAG_OWN_REALTY','WEEKDAY_APPR_PROCESS_START','NAME_CONTRACT_TYPE','HOUSETYPE_MODE','NAME_FAMILY_STATUS','TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TARGET'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n",
    "for train_index, test_index in split.split(df, df['TARGET']):\n",
    "    train = df.loc[train_index]\n",
    "    test = df.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop(['TARGET'], axis=1)\n",
    "y_train = train['TARGET'].copy()\n",
    "x_test = test.drop(['TARGET'], axis=1)\n",
    "y_test = test['TARGET'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip = Pipeline([\n",
    "    ('imputer',SimpleImputer(missing_values=np.nan, strategy='median')),\n",
    "    ('rsc',RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_attr = ['DAYS_BIRTH','REGION_RATING_CLIENT_W_CITY','EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3']\n",
    "num_attr = list(df.select_dtypes('float64'))+list(df.select_dtypes('int64'))\n",
    "cat_attr = list(df.select_dtypes('object'))\n",
    "num_attr.remove('TARGET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = ColumnTransformer([\n",
    "    ('num',pip, num_attr),\n",
    "    ('cat', OneHotEncoder(), cat_attr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(x_train.select_dtypes('object')):\n",
    "    x_train[col].fillna(\"No College\", inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_pipeline.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(full_pipeline, 'sklearn_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train\n",
    "\n",
    "smote = SMOTE(random_state=0)\n",
    "X_train, y_train = smote.fit_sample(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(y_train).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(40, activation='relu', input_shape=(1,X_train.shape[1])),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(30, activation='relu',kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model10.fit(X_train,\n",
    "                      y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size= 40,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10),\n",
    "                               tfdocs.modeling.EpochDots(),\n",
    "                               tf.keras.callbacks.ModelCheckpoint(\"weights.best.hdf5\", \n",
    "                                                                   monitor='accuracy', \n",
    "                                                                   verbose=0, \n",
    "                                                                   save_best_only=True, \n",
    "                                                                   save_weights_only=False, \n",
    "                                                                   mode='max', \n",
    "                                                                   periode=1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Courbe Apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10.save('Modeles\\\\model10.h5')\n",
    "model10 = tf.keras.models.load_model('Modeles\\\\model10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation du modele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in list(x_test.select_dtypes('object')):\n",
    "    x_test[col].fillna(\"No College\", inplace = True) \n",
    "X_test = full_pipeline.transform(x_test)\n",
    "\n",
    "X_test = X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model10.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print('scores',scores),\n",
    "    print('moyenne',scores.mean())\n",
    "    print('ecart type',scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_grid(grid):\n",
    "    cvr = grid.cv_results_\n",
    "    for mean_score, params in zip(cvr['mean_test_score'], cvr['params']):\n",
    "        print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = SGDClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model1, X_train, y_train, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DecisionTreeClassifier(max_features=7, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model2, X_train, y_train, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_features':np.arange(4,10)}\n",
    "\n",
    "grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5,  scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "display_grid(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = KNeighborsClassifier(n_neighbors=8, metric='euclidean', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model3, X_train, y_train, scoring='neg_mean_squared_error', cv=10, n_jobs=-1)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_neighbors':np.arange(7,10),\n",
    "             'metric':['euclidean','manhattan']}\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=5,  scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "display_grid(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = RandomForestClassifier(n_estimators=12, max_features=5,  n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model4, X_train, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'n_estimators':np.arange(11,14),\n",
    "             'max_features':np.arange(5,8)}\n",
    "\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, cv=5,  scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(grid.best_params_)\n",
    "display_grid(grid)\n",
    "gridRandomForest = grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoostClassifier CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model5, X_train, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = GaussianNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GaussianNB CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model6, X_train, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = CatBoostClassifier(iterations=38, learning_rate=1, depth=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost CrossVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model7, X_train, y_train, scoring='neg_mean_squared_error', cv=5, n_jobs=-1)\n",
    "rf_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(rf_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'iterations':np.arange(35,40),\n",
    "             'learning_rate':np.arange(1,3)}\n",
    "\n",
    "grid = GridSearchCV(CatBoostClassifier(), param_grid, cv=5,  scoring='neg_mean_squared_error', return_train_score=True, n_jobs=-1,verbose=2)\n",
    "grid.fit(X_train, y_train,verbose=False)\n",
    "print(grid.best_params_)\n",
    "display_grid(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# votingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#voting hard voting, soft voting\n",
    "model11 = VotingClassifier([#('sgd', model1), \n",
    "                          ('tree', model2),\n",
    "                          ('kn', model3),\n",
    "                          ('rdforest',model4),\n",
    "                          #('ada',model7),\n",
    "                          #('bayes',model6)\n",
    "],\n",
    "                         voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for col in list(x_test.select_dtypes('object')):\n",
    "#    x_test[col].fillna(\"No College\", inplace = True) \n",
    "#X_test = full_pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in (model1, \n",
    "              model2,\n",
    "              model3, \n",
    "              model4, \n",
    "              model5, \n",
    "              model6,\n",
    "              model7,\n",
    "              model11):\n",
    "    model.fit(X_train, y_train)\n",
    "    print(model.__class__.__name__, model.score(X_test, y_test))\n",
    "    print(confusion_matrix(y_test, model.predict(X_test)))\n",
    "    \n",
    "print('model10')\n",
    "model10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarde des modeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in (model1, \n",
    "              model2,\n",
    "              model3, \n",
    "              model4, \n",
    "              model5, \n",
    "              model6,\n",
    "              model7,\n",
    "              model11):\n",
    "    joblib.dump(model, 'Modeles\\\\model'+model.__class__.__name__)\n",
    "# loaded_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Courbes d' apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, train_score, val_score = learning_curve(model4, X_train, y_train, train_sizes=np.linspace(0.1,1.0,10), cv=4, n_jobs=-1)\n",
    "\n",
    "plt.plot(N, train_score.mean(axis=1), label='train')\n",
    "plt.plot(N, val_score.mean(axis=1), label='validation')\n",
    "plt.xlabel('train_sizes')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FeaturesImportances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes_feat = list(full_pipeline.transformers_[1][1].get_feature_names(full_pipeline.transformers_[1][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importances = gridRandomForest.best_estimator_.feature_importances_\n",
    "attr = num_attr + cat_attr\n",
    "print(attr)\n",
    "sorted(zip(features_importances,  attr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = cat_attributes_feat + num_attr\n",
    "feature = [str(columns) for columns in attr]\n",
    "importance = np.round(features_importances * 100, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({'feature' : feature, 'importance' : importance})\n",
    "\n",
    "feature_importance_sorted = feature_importance.sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "feature_importance_sorted.plot.barh(x = 'feature', y = 'importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_sorted[feature_importance_sorted['importance']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelSelection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare an array with all the algorithms\n",
    "models = []\n",
    "models.append(('SGD', SGDClassifier()))\n",
    "models.append(('DTC', DecisionTreeClassifier()))\n",
    "models.append(('KNC', KNeighborsClassifier()))\n",
    "models.append(('RFC', RandomForestClassifier()))\n",
    "models.append(('ABC', AdaBoostClassifier()))\n",
    "models.append(('GNB', GaussianNB()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the configuration to run the test\n",
    "seed = 7\n",
    "results = []\n",
    "names = []\n",
    "X = X_train\n",
    "Y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every algorithm is tested and results are\n",
    "# collected and printed\n",
    "for name, model in models:\n",
    "kfold = model_selection.KFold(\n",
    "n_splits=10, random_state=seed)\n",
    "cv_results = model_selection.cross_val_score(\n",
    "model, X, Y, cv=kfold, scoring='accuracy')\n",
    "results.append(cv_results)\n",
    "names.append(name)\n",
    "msg = \"%s: %f (%f)\" % (\n",
    "name, cv_results.mean(), cv_results.std())\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ORGANIZATION_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>DAYS_BIRTH</th>\n",
       "      <th>REGION_RATING_CLIENT_W_CITY</th>\n",
       "      <th>EXT_SOURCE_1</th>\n",
       "      <th>EXT_SOURCE_2</th>\n",
       "      <th>EXT_SOURCE_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advertising</td>\n",
       "      <td>F</td>\n",
       "      <td>-19751</td>\n",
       "      <td>1</td>\n",
       "      <td>0.427626</td>\n",
       "      <td>0.814762</td>\n",
       "      <td>0.694093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ORGANIZATION_TYPE CODE_GENDER  DAYS_BIRTH  REGION_RATING_CLIENT_W_CITY  \\\n",
       "0       Advertising           F      -19751                            1   \n",
       "\n",
       "   EXT_SOURCE_1  EXT_SOURCE_2  EXT_SOURCE_3  \n",
       "0      0.427626      0.814762      0.694093  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "loaded_pipeline = joblib.load('sklearn_pipeline.pkl')\n",
    "loaded_model = joblib.load('modelRandomForestClassifier')\n",
    "val = {'ORGANIZATION_TYPE':['Advertising'],\n",
    "       'CODE_GENDER':['F'],\n",
    "       'DAYS_BIRTH':[-19751],\n",
    "       'REGION_RATING_CLIENT_W_CITY':[1],\n",
    "       'EXT_SOURCE_1':[0.427626],\n",
    "       'EXT_SOURCE_2':[0.814762],\n",
    "       'EXT_SOURCE_3':[0.694093]}\n",
    "val = pd.DataFrame(data=val)\n",
    "val.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = loaded_pipeline.transform(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = loaded_model.predict_proba(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.83333333 0.16666667]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
